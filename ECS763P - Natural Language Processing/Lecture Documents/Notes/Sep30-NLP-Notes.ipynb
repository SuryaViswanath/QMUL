{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de36cc68-ace2-4555-a9d3-ee5df2530d1b",
   "metadata": {},
   "source": [
    "# [ECS763P] - Natural Language Processing\n",
    "\n",
    "## Lecture 2 notes:\n",
    "\n",
    "Running points:\n",
    "-  Preprocessing text helps in removing unnecessary information\n",
    "-  shakespeare corpus used `'d` for past tennse >>intersting<<\n",
    "-  Maximum matching algorithm works well with chinese language, but not really with the english. So understand and analyse the language to see which one to use\n",
    "-  **language is ambiguous**; There are a lot of problems in the pre-processing. Look at those\n",
    "-  Why is stemming the way it is? who defines the rules for these things? why is it faster? Compare and evaluate the lemmatization and stemming\n",
    "-  so does stemming and lemmatization not work for anything other than classification?\n",
    "-  how can we optimise the model generalisation over data\n",
    "-  What are features? how to choose the features and what are the different ways to identify new features and also pootentially create new ones\n",
    "-  Evaluation metrics, how to understand\n",
    "-  how to choose weights\n",
    "-  Error Analysis - how to balance the dataset so that the classification works well"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb68393-d63b-41ef-a3dc-f35f34339551",
   "metadata": {},
   "source": [
    "### Let's get started\n",
    "\n",
    "When you are working with problems associated with the language, we rely on the techniques associated with the natural language processing. This ability to understand the language helps in solving complex problems. \n",
    "\n",
    "   <div style=\"text-align: center;\">\n",
    "       <img src=\"images/power-meme.jpg\" alt=\"Example Image\" width=\"300\" height=\"150\"/>\n",
    "   </div>\n",
    "\n",
    "\n",
    "\n",
    "As the saying goes, `With great power comes great responsibility`, Lets give it a new form in the case of NLP -> `With great solution comes, great problems.`\n",
    "\n",
    "Solving a language problem comes with it's own challenges for ex: \n",
    "1. **Inconsistent use of words** - varying usage of words\n",
    "   <div style=\"text-align: center;\">\n",
    "       <img src=\"images/incosistent-use-of-words.png\" alt=\"Example Image\" width=\"300\" height=\"150\"/>\n",
    "   </div>\n",
    "\n",
    "2. **Linguistic variations** - meaning is similar (**_it is similar, not the same_**), the way in which it is constructed is different\n",
    "   <div style=\"text-align: center;\">\n",
    "       <img src=\"images/similar-sentences.png\" alt=\"Example Image\" width=\"500\" height=\"300\"/>\n",
    "   </div>\n",
    "\n",
    "3. **Redundant information in data** - most often than not, there is a lot of information that is repeated so much so that the corpus/corpora should be cleaned. One such example is **stopword removal**\n",
    "   <div style=\"text-align: center;\">\n",
    "       <img src=\"images/stopwords.png\" alt=\"Example Image\" width=\"120\" height=\"150\"/>\n",
    "   </div>\n",
    "\n",
    "4. **Tokenization** - Tokenization is an important step during data preprocessing as it helps the model understand the data much better. However, what you need to understand here is there are a lot of nuances. These nuances will be covered just in a little while.\n",
    "\n",
    "5. **Normalization** - In simple terms, it is making sense of what is given. There are two different types at a high level:\n",
    "   - Symmetric normalization\n",
    "   - Asymmetric normalization\n",
    "\n",
    "   More in detail a little later.\n",
    "\n",
    "6. **Sentence segmentation** - When punctuation comes in your way, and not having it is the best. We will dive a little deeper into this too in the following sections.\n",
    "\n",
    "\n",
    "Now that we kind of outlined that there are a lof of challenges, let's put all these problems under 1 umbrella. So let me think of a name to give\n",
    "\n",
    "...thinkinnnnnnng\n",
    "\n",
    "...thinkinnnnnnnggggggg\n",
    "\n",
    "...thinn\n",
    "\n",
    "> **Text Preprocessing**\n",
    "\n",
    "Voila!!! Chef's kiss\n",
    "\n",
    "Alright coming back, I know I will bomb my first stand up gig but hey! I am doing my education so hopefully I earn better (not)\n",
    "\n",
    "So now, coming back to the story. This `Text Preprocessing` plays a crucial role in getting the data to perform for instance a text classification problem.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Even though there are a lot of problems, all these problems have solutions if we understand fully well what is causing the issue in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3213c-faf9-4f8d-9b85-f3f3498c174b",
   "metadata": {},
   "source": [
    "#### Tokenization\n",
    "Tokenization is the dividing the sentences in such a way that the model is able to understand the data. This is very important because it helps with learning patterns from the corpus and build model that could predict the class label accurately. \n",
    "\n",
    "But don’t let this fool you—it’s not just a quick slice with a regex knife! You’ve got to keep those pieces in shape so they don’t lose meaning. I mean, what’s the point of slicing up \"England, Englands, and England’s\" if your model thinks they’re three different countries? \n",
    "\n",
    "   <div style=\"text-align: center;\">\n",
    "       <img src=\"images/tokenization-issues.png\" alt=\"Example Image\" width=\"350\" height=\"200\"/>\n",
    "   </div>\n",
    "\n",
    "\n",
    "If you see the image carefully, how do you put a finger and say the rule for tokenizing \n",
    "\n",
    "Not easy right!\n",
    "\n",
    "so understanding the language, and also the type of problem for which the data is being prepared plays a huge role. There are various tokenizers that are available\n",
    "\n",
    "### Some Common Tokenizers\n",
    "\n",
    "| Tokenizer        | Library          | Features                                        |\n",
    "|------------------|------------------|-------------------------------------------------|\n",
    "| <span style=\"color:green\">NLTK Tokenizer</span>   | NLTK             | Word, sentence, regex, treebank tokenization    |\n",
    "| <span style=\"color:blue\">SpaCy Tokenizer</span>  | SpaCy            | Efficient, customizable, multi-language support |\n",
    "| <span style=\"color:#DAA520\">Transformers</span>     | Hugging Face     | Subword tokenization (BPE, WordPiece, Unigram)  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b42100-8cf1-4f64-b9ac-ee04aa6c6276",
   "metadata": {},
   "source": [
    "**Before we dive into the what is text classification problem. Write down what you understand of text classification in a sentence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb99d233-45c4-497e-95f9-73a8a9529745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What do you understand from text classification? separting stuff into groups\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yourTake(input('What do you understand from text classification?').lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75357b6a-6ff5-4631-be0f-852109bc85e5",
   "metadata": {},
   "source": [
    "### So what is Text classification?\n",
    "![Text Classification](images/what-is-text-classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bccca-1284-4134-b89f-eeb4f212784f",
   "metadata": {},
   "source": [
    "Text classification is classifying the text ot it's concerned group. For instance in the case of students, based on the id number provided there is information that would reflect which department they belong to - ecxxxxxx is your number so I know you belong to the stream of electronics and computer science department.\n",
    "\n",
    "but wait did you not get the question that I got while writing this example - `How do you know that the id belonged to the Electronics and Computer science department`. If you know please answer below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12a5c342-0f40-4686-8683-6257cd21ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "How did you know? don't know\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In our case the first 2 characters help us'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smartyPants(input(\"How did you know?\").lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72ba93c-8a00-4842-8bde-fde58a5f2e0f",
   "metadata": {},
   "source": [
    "Hence there are 2 ways in which we can train the model\n",
    "1. Supervised Learning\n",
    "2. Unsupervised Learning\n",
    "\n",
    "\n",
    "The id card example is a case of supervised learning. Today let us dive a little into how supervised learning works\n",
    "\n",
    "\n",
    "_Text preprocessing_ that was done prior helps the machine to identify the patterns and there by assign a designated label to which it may belong. This way of a controlled environment where you know what it belongs to is called as a supervised learning\n",
    "\n",
    "Hence, \n",
    "\n",
    "![Classification image](images/Text_Classification_Machine_Learning_NLP.png)\n",
    "\n",
    "Here the dataset is represented as d, and the final labels as C, hence for any new example that comes our way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3754f8d-a887-4023-8fad-f1695b301b1e",
   "metadata": {},
   "source": [
    "$$\n",
    "c^* \\in C\n",
    "$$\n",
    "where:\n",
    "- $( C )$ is the set of all possible classes.\n",
    "- $( c^* )$ is the target class that the algorithm predicts for a given input \\( x \\).\n",
    "\n",
    "The classification task can be summarized as finding a function ( f: x &rarr; C)\n",
    " that maps input data points $( x )$ from the feature space $( X )$ to their corresponding classes in $( C )$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a7afa9-3236-4643-9726-fe9d93e10e83",
   "metadata": {},
   "source": [
    "So yeah, that's about it; that is how we train the model. Goodbye, thank you!<br>\n",
    "<p style=\"text-align: center;\">\n",
    "    <img src=\"images/bye-girl.gif\" alt=\"Bye\" width=\"300\"/> <!-- Adjust the width as needed -->\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43446e72-ce85-43fa-811f-d50b6a9dca87",
   "metadata": {},
   "source": [
    "Well not so easy my friend, this doesn't end our problems. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let us now dive into what it takees to do the classification, what are the stages that are there before we get the final product out\n",
    "\n",
    "![Stages of development](images/stages.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e42eea-9053-4fa6-9d1a-53804097b1c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa076aaf-58c0-4c2e-9a11-4b35ae4d91a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc225e7-aed0-45c2-ab20-910ae29de341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c54e64-87af-4886-a9aa-1c50cdc4238f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17634a0a-6afa-4da0-8f23-49eb0663473a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d687d-af0f-4ee8-96bc-a2a40b50a347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a997fba-d9f1-4749-9b7d-0df8913baf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec3f1c-e289-4a7a-83b8-f95bd3082b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bc28f-1c51-47d2-ae9b-6a09cce9275e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee837fa-5760-452a-a393-445ae91f6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yourTake(userPhrase):\n",
    "    words_set = {'grouping', 'organizing', 'labeling', 'dividing', 'arranging', \n",
    "             'assigning', 'sorting', 'categorizing', 'classifying', 'separating'}\n",
    "    if any(word in userPhrase.split() for word in words_set):\n",
    "        return \"Nice work, let's expand on that\"\n",
    "    else:\n",
    "        return \"Close, let's dive deeper into it\"\n",
    "\n",
    "\n",
    "def smartyPants(userPhrase):\n",
    "    if ('ec' in userPhrase) or ('first 2' in userPhrase):\n",
    "        return \"Exactly, the first 2 characters\"\n",
    "    else:\n",
    "        return \"In our case the first 2 characters help us\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fdbf1e-95de-4899-932d-916961f354dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
